version: '3.8'

services:
  ai-github-analyzer:
    # Option 1: Build locally (currently enabled due to push issues)
    build:
      context: .
      dockerfile: Dockerfile
    
    # Option 2: Use pre-built image from Docker Hub (enable when push succeeds)
    # image: smukherjee2004/ai-github-analyzer:latest
    
    container_name: ai-github-analyzer
    ports:
      - "8501:8501"
    environment:
      # OpenRouter API Key - set this in your .env file or pass as environment variable
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      
      # Optional: Override default model
      - DEFAULT_MODEL=${DEFAULT_MODEL:-mistralai/mixtral-8x7b-instruct}
      
      # Optional: Logging configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # Optional: Cache settings
      - CACHE_ENABLED=${CACHE_ENABLED:-true}
      - CACHE_TTL=${CACHE_TTL:-3600}
      
      # Optional: Analysis limits
      - MAX_FILES_DEFAULT=${MAX_FILES_DEFAULT:-100}
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-1}
      - ANALYSIS_TIMEOUT_MINUTES=${ANALYSIS_TIMEOUT_MINUTES:-30}
      
      # Streamlit configuration
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_HEADLESS=true
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
    
    volumes:
      # Mount for persistent storage of analysis reports
      - ./sample_output:/app/sample_output
      
      # Optional: Mount repos directory for persistent repository storage
      - ./repos:/app/repos
    
    restart: unless-stopped
    
    # Resource limits (adjust based on your needs)
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

# Optional: Add a reverse proxy (uncomment if needed)
# nginx:
#   image: nginx:alpine
#   container_name: ai-github-analyzer-proxy
#   ports:
#     - "80:80"
#     - "443:443"
#   volumes:
#     - ./nginx.conf:/etc/nginx/nginx.conf
#   depends_on:
#     - ai-github-analyzer
#   restart: unless-stopped

networks:
  default:
    name: ai-github-analyzer-network
